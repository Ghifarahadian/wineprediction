{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57819a0-2c11-4ecc-810c-6fbeaaa68311",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r /root/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "016efa89-50b4-458c-92cf-2b9412f452ed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "E: Unable to locate package vim\n"
     ]
    }
   ],
   "source": [
    "!apt install vim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb884d8-4880-4045-884a-bca3f3005b59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644181bc-33e4-4ff4-8e9c-bc7c639a9004",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "# Setting the working directory\n",
    "base_path = \"/home/sagemaker-user/\"\n",
    "import os\n",
    "os.chdir(base_path)\n",
    "\n",
    "submission = pd.read_csv(\"data/raw/test/test.csv\")[[\"Id\"]]\n",
    "test = pd.read_csv(\"data/processed/test/test.csv\")\n",
    "\n",
    "# Load the saved model from disk\n",
    "latest_model = os.listdir(\"models\")[1]\n",
    "with open(f\"models/{latest_model}/model.bin\", 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "\n",
    "pred_val = model.predict(test)\n",
    "\n",
    "submission[\"quality\"] = pred_val\n",
    "\n",
    "def scale(df):\n",
    "    df[\"quality\"] = df[\"quality\"] + 3\n",
    "    return df\n",
    "\n",
    "submission = scale(submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b199c5-3297-4724-a83d-febe81327ce9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "9b842661-ac79-4470-8fe1-440a7d6ea319",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2023-02-05_07-12-57', '2023-02-05_07-17-07', '2023-02-05_07-29-38']"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(os.listdir(\"models/lgbm\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14296229-e7ac-4fa0-99c1-4cfe8f69c161",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('data/output/submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "6f6edd93-122b-4076-8e6e-099952f1f173",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-05 07:12:55,177]\u001b[0m A new study created in memory with name: no-name-2fd8ceb0-4b53-4515-b223-009d7c3c701e\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.4779971398496391, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.4779971398496391\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6073410675936389, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6073410675936389\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.454665595286564, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.454665595286564\n",
      "[LightGBM] [Warning] feature_fraction is set=0.18409412753724097, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.18409412753724097\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=69, min_child_samples=14 will be ignored. Current value: min_data_in_leaf=69\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.4779971398496391, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.4779971398496391\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6073410675936389, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6073410675936389\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.454665595286564, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.454665595286564\n",
      "[LightGBM] [Warning] feature_fraction is set=0.18409412753724097, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.18409412753724097\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=69, min_child_samples=14 will be ignored. Current value: min_data_in_leaf=69\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.4779971398496391, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.4779971398496391\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6073410675936389, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6073410675936389\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.454665595286564, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.454665595286564\n",
      "[LightGBM] [Warning] feature_fraction is set=0.18409412753724097, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.18409412753724097\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=69, min_child_samples=14 will be ignored. Current value: min_data_in_leaf=69\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.4779971398496391, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.4779971398496391\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6073410675936389, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6073410675936389\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.454665595286564, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.454665595286564\n",
      "[LightGBM] [Warning] feature_fraction is set=0.18409412753724097, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.18409412753724097\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=69, min_child_samples=14 will be ignored. Current value: min_data_in_leaf=69\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-05 07:12:57,094]\u001b[0m Trial 0 finished with value: 0.3522418597474428 and parameters: {'lambda_l1': 0.4779971398496391, 'lambda_l2': 3.454665595286564, 'num_leaves': 42, 'feature_fraction': 0.18409412753724097, 'bagging_fraction': 0.6073410675936389, 'bagging_freq': 8, 'min_child_samples': 14, 'min_data_in_leaf': 69, 'max_depth': 10}. Best is trial 0 with value: 0.3522418597474428.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.4779971398496391, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.4779971398496391\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6073410675936389, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6073410675936389\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.454665595286564, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.454665595286564\n",
      "[LightGBM] [Warning] feature_fraction is set=0.18409412753724097, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.18409412753724097\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=69, min_child_samples=14 will be ignored. Current value: min_data_in_leaf=69\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "import xgboost as xgb \n",
    "import lightgbm as lgbm\n",
    "from HROCH import PHCRegressor\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "import datetime\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "# Suppressing warnings\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "# Setting the working directory\n",
    "import os\n",
    "try:\n",
    "    base_path = \"/home/sagemaker-user/\"\n",
    "    os.chdir(base_path)\n",
    "except:\n",
    "    base_path = \"/root/\"\n",
    "    os.chdir(base_path)\n",
    "\n",
    "# Loading the data\n",
    "train = pd.read_csv(\"data/processed/train/train.csv\")\n",
    "\n",
    "# Setting the target and feature variables\n",
    "target = \"quality\"\n",
    "features = [col for col in train.columns if col != target]\n",
    "n_classes = len(train[target].unique())\n",
    "\n",
    "def objective_lgbm(trial):    \n",
    "    params_lgbm = {\n",
    "        'lambda_l1': trial.suggest_float('lambda_l1', 0.0, 1.0),\n",
    "        'lambda_l2': trial.suggest_float('lambda_l2', 1.0, 10.0),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 10, 100),\n",
    "        'feature_fraction': trial.suggest_float('feature_fraction', 0.0, 1.0),\n",
    "        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.0, 1.0),\n",
    "        'bagging_freq': trial.suggest_int('bagging_freq', 1, 10),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 10, 100),\n",
    "        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 10, 100),\n",
    "        'max_depth': trial.suggest_int('max_depth', 1, 10),\n",
    "        'num_iterations': 10000,\n",
    "        'objective' : \"multiclass\",\n",
    "        'metric' :'multi_logloss'\n",
    "    }\n",
    "        \n",
    "    cv = StratifiedKFold(5, shuffle=True, random_state=42)\n",
    "    fold_scores = []\n",
    "    for i, (train_idx, val_idx) in enumerate(cv.split(train[features], train[target])):\n",
    "        X_train, y_train = train.loc[train_idx, features],train.loc[train_idx, target]\n",
    "        X_val, y_val = train.loc[val_idx, features],train.loc[val_idx, target]\n",
    "\n",
    "        model = lgbm.LGBMClassifier(**params_lgbm)\n",
    "        model.fit(X_train,\n",
    "                  y_train,\n",
    "                  eval_set=[(X_val, y_val)],\n",
    "                  early_stopping_rounds=50,\n",
    "                  verbose=500)\n",
    "\n",
    "        pred_val = model.predict(X_val)\n",
    "\n",
    "        score = cohen_kappa_score(y_val, pred_val)\n",
    "        fold_scores.append(score)\n",
    "    return np.mean(fold_scores)\n",
    "\n",
    "study = optuna.create_study(direction='maximize', sampler = TPESampler())\n",
    "study.optimize(func=objective_lgbm, n_trials=1)\n",
    "\n",
    "model = lgbm.LGBMClassifier(**study.best_params)\n",
    "model.fit(train.loc[:, features],\n",
    "                 train.loc[:, target])\n",
    "\n",
    "date_time_str = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "file_path = base_path + \"models/lgbm/\" + date_time_str\n",
    "os.mkdir(file_path)\n",
    "\n",
    "with open(file_path + '/model.bin', 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "    \n",
    "with open(file_path + \"/params.json\", 'w') as f:\n",
    "    json.dump(study.best_params, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "0aa7cffa-ec2a-4719-8892-c93d4cd0ff4f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['src',\n",
       " '.config',\n",
       " 'notebooks',\n",
       " 'models',\n",
       " '.cache',\n",
       " 'requirements.txt',\n",
       " 'data',\n",
       " '.ipynb_checkpoints',\n",
       " 'submission.csv',\n",
       " '.sagemaker-jumpstart-tasks-status.json',\n",
       " '.python_history',\n",
       " '.jupyter',\n",
       " '.ipython',\n",
       " '.aws',\n",
       " '.local',\n",
       " '.bash_history',\n",
       " '.yarnrc']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e67b1d-b8fc-4225-88bc-780730536d51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:ap-southeast-1:492261229750:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
